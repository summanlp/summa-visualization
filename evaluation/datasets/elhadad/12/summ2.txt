A quantum computer would rely on the surreal behaviour of the very small to work miracles with information .
What , though , if a computer could be built around a different kind of physics , the quantum physics that governs the weird and uncertain behaviour of atoms and sub - atomic particles ? These switches can be thought of as the digits of numbers , in which case their ons and offs are the ones and zeros of binary counting . This is why , by a fortunate contraction of the words " binary digit " , the currency of data processing is known as the " bit " . Indeed , they are organised into " logic gates " that do calculations using this algebra . Paul Benioff , at Argonne National Laboratory , in Illinois , first applied quantum theory to computers in 1981. Claude Shannon , who also worked at AT&T, set the ball rolling by investigating ways of encoding bits of information so that they would resist errors during transmission down telephone lines . 