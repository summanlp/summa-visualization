A quantum computer would rely on the surreal behaviour of the very small to work miracles with information . The underlying logic of the programs - - the binary choices that control the way a computer counts and calculates - - would work just as well ( if a lot more slowly ) in a device that shuttled ball - bearings instead of electrons . These switches can be thought of as the digits of numbers , in which case their ons and offs are the ones and zeros of binary counting . This is why , by a fortunate contraction of the words " binary digit " , the currency of data processing is known as the " bit " . Indeed , they are organised into " logic gates " that do calculations using this algebra . Paul Benioff , at Argonne National Laboratory , in Illinois , first applied quantum theory to computers in 1981. One of the big advantages of recording and processing information digitally is that it is difficult to make a mistake ( electronic " ones " are not that easily turned into " zeros " ) , and surprisingly easy to design ways to recognise and correct any mistake that is made .
