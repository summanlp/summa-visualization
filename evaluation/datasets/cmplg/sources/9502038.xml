<?xml version='1.0'?>
<!DOCTYPE MINIMAL-DOC SYSTEM "mini.dtd">
<MINIMAL-DOC>
<TITLE>Implementation and evaluation of a German HMM for POS disambiguation</TITLE>
<ABSTRACT>
<P>
A German language model for the Xerox HMM tagger is presented.  This
model's performance is compared with two other German taggers with
partial parameter re-estimation and full adaption of parameters from
pre-tagged corpora. The ambiguity types resolved by this model are
analysed and compared to ambiguity types of English and French.
Finally, the model's error types are described. I argue that although
the overall performance of these models for German is comparable to
results for English and French, a more exact analysis demonstrates
important differences in the types of disambiguation involved for German.
</P>
</ABSTRACT>
<BODY>
<DIV ID="1" DEPTH="1" R-NO="1"><HEADER>  Background </HEADER>
<P>
Since the late '80s part-of-speech (POS) disambiguation using Hidden
Markov Models (HMM) has been a widespread method for tagging texts. Despite
this fact, little work has been done so far toward employing this
 technology for the disambiguation of German texts (cf. <REF/>,  <REF/>). Earlier work of the author (Feldweg 1993 and 1995) within the framework
of a project on corpus based development of lexical knowledge bases
(ELWIS) has produced LIKELY, a straightforward implementation of the
Viterbi algorithm employing an HMM whose parameters were obtained from
a pre-tagged text corpus.  Since then the original tag set was
redefined, making the tagged corpus used to train the LIKELY tagger
obsolete.
</P>
<P>
Within a current project on adapting bilingual dictionaries for online
comprehension assistance (COMPASS, LRE 62-080), the need arose for a
POS-disambiguator to facilitate a context sensitive dictionary
look-up system.  As the COMPASS project makes ample use of Xerox
technology for its core look-up engine and for POS disambiguation for
languages other than German, the obvious thing to do was to develop a
German language model for the Xerox tagger.
</P>
<P>
The following section describes the implementation of this new
 model. In section <CREF/> the results obtained using the new model are compared with the results from previous models. An
analysis of the types of disambiguation involved in these models
 is presented in section <CREF/>. The model's error  types are analysed in section <CREF/>, and conclusions  are drawn in section  <CREF/>. 
</P>
</DIV>
<DIV ID="2" DEPTH="1" R-NO="2"><HEADER>    Implementation of the German language model
</HEADER>
<P>
The version of the Xerox tagger used for the implementation described
 here is the DDS Tagger version 1.1 <REF/>. This version differs from the current version (1.2) of the Xerox Tagger as
described in
 <REF/> in that the DDS Tagger accommodates lexicons and class guessers in the form of external finite-state transducers.
Implementing a new language model for this tagger involves supplying:
</P>
<P>
1.
a definition of the tag set to be used by the HMM,
2.
a lexicon listing word forms with their equivalence classes, that is
the list of POS tags that can be assigned to the word form,
3.
a class guesser that assigns equivalence classes to words not
       covered by the lexicon,
4.
a set of initial transition biases,
5.
a set of initial symbol biases,
6.
a sufficiently large text for training the HMM,
7.
a reference text with correctly assigned POS tags,
8.
a tokenizer that recognizes words in free text.
</P>
<P>
The following paragraphs describe these components in more detail.
</P>
<P>
(1)        
The tag set used in the implementation is the smaller version of the
two tag sets developed jointly by the Universities of Stuttgart and
 Tbingen, referred to as the ELWIS tag set (cf. <REF/>  and <REF/>). It consists of a total of 42 POS tags plus three tags for punctuation and a special tag for truncated words. The
 tags used in the ELWIS tag set are given in table <CREF/>. 
</P>
<IMAGE TYPE="TABLE"/>
<IMAGE TYPE="TABLE"/>
<P>
Detailed guidelines on the use of the individual tags are available in
 <REF/>. 
</P>
<P>
(2)        
For each word form the lexicon gives the set of POS tags that can be
assigned to that word. This set may consist of one (for unambiguous
words) or more tags and is referred to as the word's equivalence
class.  The lexicon used in this implementation was derived from
Lingsoft's GERTWOL morphological analyzer, which uses finite state
transducers, by mapping the morpho-syntactic labels generated by
GERTWOL onto the ELWIS tag set. The lexicon is realized as a finite
state transducer for the DDS Tagger. Alternative mapping rules were
developed to generate a lexicon with ELWIS tags from the German
lexical database of the Centre for Lexical Information
 <REF/>. 
</P>
<P>
(3)        Class guessers for the Xerox tagger assign potential POS
tags to unknown words according to a surface analysis of the word
form. In addition to the common practice of mapping POS tags according
to the words' suffixes, this implementation makes use of the case of
the initial letter of a word -- which is highly significant for POS
assignment in German.  The class guesser also takes care of
POS-assignment for abbreviations, special symbol sequences and
language external material in the text.
The class guesser, like the lexicon, is a  finite state transducer.
</P>
<P>
(4)        
The model is trained using a set of initial transition
biases, including both positive and negative constraints on tag
sequences.  Although the model can be trained without initial biases,
the performance of the resulting model increases significantly if
appropriate initial biases are used.
</P>
<P>
The biases in the model consisted for the most part in specifications
of the most plausible successor tags for each tag in the tag set.
They were constructed manually and refined in a series of subsequent
training and evaluation runs.
</P>
<P>
(5)        
Initial symbol biases are an additional set of biases used to define
preferences for tag assignment given a particular equivalence
class. Only a very few symbol biases were defined before evaluation of
the first training runs, mainly to reflect biases towards equivalence
classes used in the class guesser. The majority of symbol biases were
added to correct misguided biases chosen during the training
processes.
</P>
<P>
(6)        
The two texts used for training the HMM were selected from the German
 data contained on the ECI's Multilingual CD-ROM <REF/>: a 200,000 and 2,000,000 word sample from Summer 1992 issues of the
German newspaper Frankfurter Rundschau.
</P>
<P>
(7)        
The reference texts were also taken from the
Frankfurter Rundschau, but do not overlap with the training
texts. The reference texts amount to a total of approximately 20,000
running words, which were manually tagged and checked.
</P>
<P>
(8)        
The current version of the implementation uses a
straightforward tokenizer accepting one line per token.  Training
texts are pretokenized using an external tokenizer written in lex.
</P>
<DIV ID="2.1" DEPTH="2" R-NO="1"><HEADER>  Performance </HEADER>
<P>
The best results of this implementation were obtained running 20
iterations of training over the 200,000 word training text, using a
total of 50 transition and 17 symbol biases. With this configuration
of training parameters, the resulting HMM assigned <EQN/>incorrect tags when run on the reference texts and compared with the
manually assigned tags.
</P>
</DIV>
</DIV>
<DIV ID="3" DEPTH="1" R-NO="3"><HEADER>    Comparison with other German models
</HEADER>
<P>
The main advantage of the Xerox tagger when compared with earlier
implementations of HMM taggers is that it can be trained using
untagged text. However, the performance of the resulting HMM is very
poor if no initial biases are used to help the training process find
suitable parameters.
</P>
<P>
For comparison, the evaluation procedure used to evaluate the
implementation of the HMM tagger described in the preceding section
was repeated without using any of the initial biases. The result was a
poor performance of the resulting HMM with an error rate of
<EQN/>.
</P>
<P>
Choosing initial biases to help train a model is a subtle task in that
it not only requires sound knowledge of the tag set used and the
target language the model is aiming at, but it also requires a
``feel'' for how the initial biases may be modified during a given
number of training iterations. It is also sometimes frustrating that
the linguistic knowledge used to create the initial biases gets
``optimized'' or ``trained'' away in subsequent iterations of
training.
</P>
<P>
To overcome these disadvantages, hybrid technologies have been
developed that combine free text training methods with parameter
estimation from pre-tagged texts. In such a setting, initial
transition and symbol biases are replaced by frequencies of tag
sequences and tag instantiation from a relatively small pre-tagged
corpus. The counted frequencies are taken as an approximation to the
model's probabilities and get smoothed in a small number
of training iterations.
</P>
<P>
In order to see what could be gained for a German language model by such
a hybrid technology, I used extensions to the Xerox tagger
developed at the University of Stuttgart that facilitate
initialization of an HMM with values obtained from a pre-tagged
 corpus (cf. <REF/>). Initial parameters were obtained by counting transition and symbol frequencies
in a manually tagged 24,000 word corpus taken from the newspaper
Stuttgarter Zeitung, that was kindly made available by the
University of Stuttgart. These initial parameters were adjusted in a
single training iteration using Xerox's Baum-Welch implementation for
parameter re-estimation. The texts used for training and as a
reference for evaluation were the same as the ones used in the
 implementation described in section <CREF/>. The resulting HMM had an error rate of <EQN/>.
The superior
performance of this model confirms results presented by
 <REF/>, <REF/>,  and <REF/> for English: empirically obtained initial values for transition and output probabilities with a small number of
training iterations lead to significantly better results than
intuitively generated biases do.
</P>
<P>
On the other end of the scale of parameter production for HMM POS
disambiguators is the extraction of parameters exclusively on the
basis of (larger) pre-tagged text corpora, with no Baum-Welch
re-estimation involved. Such an implementation is described in earlier
 work of the author (cf. <REF/> and  <REF/>). For this model error rates of 
<!-- MATH: $3.16\;\%-7.29\;\%$ -->
<EQN/>
(depending on the coverage of the underlying
lexicon) were reported. These results, however, are not directly
comparable to the implementations described in this paper, since the
tag sets employed differ to some extent.
</P>
</DIV>
<DIV ID="4" DEPTH="1" R-NO="4"><HEADER>    Assessment of ambiguity types
</HEADER>
<P>
In the preceding sections the evaluation of the model was purely quantitative.
Performance was measured as the percent of mismatches between the output
generated by the HMM and the tags assigned by manual tagging. Although
this error rate is an appropriate measure for the performance of an
HMM given a particular reference text, it says little about the amount
of disambiguation done by the tagger, and nothing about the
ambiguity types that were involved in the disambiguation process.
</P>
<P>
The difficulty of disambiguation can be quantified by the ambiguity
rate: the number of possible tag assignments divided by the number of
words in a given text. The test text used to evaluate the German model
described in section
 <CREF/> has an ambiguity rate of 1.51, this is, the lexicon provides an average of 1.51 tags for each word in the
text.
</P>
<IMAGE TYPE="TABLE"/>
<IMAGE TYPE="TABLE"/>
<P>
f(ec) = relative frequency of equivalence class
</P>
<P>
In an effort to compare the German model with what is reported for
other languages, English and French tagged texts were
analysed. Both texts contained approximately 10,000 words
and were tagged using an English resp. French language model for the
Xerox tagger.
</P>
<P>
The tag set used to annotate the English text is a slightly modified
version of the Brown tag set, consisting of a total of 72 tags. The
ambiguity rate for this text is 1.41.  For the French text the tag
set described in
 <REF/> with 37 different tags is used. Here the ambiguity rate is 1.52.  In terms of ambiguity rates, the English, French, and
German texts are thus quite comparable.
</P>
<P>
In order to compare the types of ambiguities that had to be resolved
by the different language models for the HMM tagger, relative
frequency tables of equivalence classes were computed for each of the
three texts. The top most frequent equivalence classes for the three
 languages are listed in table <CREF/> together with their relative frequencies.
</P>
<P>
If the table is viewed in terms of the major word classes of noun,
verb, adjective, adverb, and closed-class forms, the following
predominant ambiguity classes for English can be distinguished:
</P>
<P>
<ITEMIZE>
<ITEM>noun vs. verb (share, offer, plan),
</ITEM>
<ITEM>adjective vs. noun (public, million, high),
</ITEM>
<ITEM>closed-class vs. noun (a),
</ITEM>
<ITEM>adjective vs. noun vs. verb (return, field),
</ITEM>
<ITEM>closed-class vs. adverb (by, about, below),
</ITEM>
<ITEM>and closed-class vs. adjective vs. adverb (round, next),
</ITEM>
</ITEMIZE>
For French the major ambiguity types are:
<ITEMIZE>
<ITEM>noun vs. verb (affaire, bout, place),
</ITEM>
<ITEM>adjective vs. noun (demi, moyen, responsable,
</ITEM>
<ITEM>adjective vs. verb (appliqu, devenu, fabriqu),
</ITEM>
<ITEM>closed-class vs. adjective (numeral un).
</ITEM>
</ITEMIZE>
The elements of the most frequent ambiguity types for German, however,
belong to the same major word classes, with only a few exception such as:
<ITEMIZE>
<ITEM>closed-class vs. adjective (numeral einen, einer),
</ITEM>
<ITEM>and verb vs. adjective (fehlgeschlagen, bekannt),
</ITEM>
</ITEMIZE>
with the latter reflecting a subtle distinction in the
German tag set (VPP vs. ADJD: participle as modifier vs. non-attributive adjectives).
</P>
<P>
The comparison of the most frequent ambiguity types shows a
significant difference between the German model on the one hand and
the English and French models on the other. In German most of the
effort is going into subclassification within major word classes,
while in English and French a good deal of disambiguation work is
devoted to separate major word classes.
</P>
</DIV>
<DIV ID="5" DEPTH="1" R-NO="5"><HEADER>    Assessment of error types
</HEADER>
<P>
The differences in ambiguity types of the models also have effects on the
types of errors produced by the German model. Again, errors mainly
affect the assignment of words to subclasses within one major word
class.
</P>
<P>
 Table <CREF/> shows the most common errors produced by the German model. The entries are sorted by decreasing frequencies
relative to the total number of mismatches between the manually and
automatically tagged texts.  The first column gives the relative
frequenciy and the second column lists the tag chosen by the German HMM
tagger. In the second column, the number following the slash indicates the
number of elements in the equivalence class from which the model had
to choose. A missing number indicates that there was only one
choice in the lexicon.  The third column show the ``correct'' tag, as
chosen by the human tagger.
</P>
<IMAGE TYPE="TABLE"/>
<IMAGE TYPE="TABLE"/>
<P>
The most common (accumulated) error is the confusion of proper nouns
and common nouns -- a result of the fact that both proper nouns and
common nouns are both capitalized in German.  The fourth line of
 table <CREF/> represents a special case of this error for which the HMM model can not be held responsible: no ambiguity was
indicated in the lexicon, so the model had nothing to choose
from. This occurs most frequently when common nouns are used as proper
nouns (e.g. in die gehobene Mittelklasse plaziert Renault ab 6. Mrz den Safrane), where one would not expect to add a
tag ``proper noun'' for every noun in the lexicon.
</P>
<P>
The second most frequent error type involves confusion of infinitives
and 1st and 3rd pers. pl. finite present tense forms.  These are
homographs in German that are notoriously hard to disambiguate within
a narrow context.
</P>
<P>
The difficulty of distinguishing between non-attributive, adjectival
usage of participles (i.e. er ist geladen) and participles
proper (i.e. er hat den Wagen geladen) was mentioned in the
preceding section. In addition a number of these forms may also be
used as finite verbs (i.e. erhalten, gehrt), and this is a
further source of errors.
</P>
<P>
Almost all of the remaining errors are misassignments within closed
classes, including well-known errors due to long distance phenomena,
such as those resulting from the confusion of relative pronouns,
demonstrative pronouns and articles in sentences like: die einmal fr die Buchproduktion erfaten
Texte or: doch der wollte nicht,
das falle auf.
</P>
</DIV>
<DIV ID="6" DEPTH="1" R-NO="6"><HEADER>    Conclusion
</HEADER>
<P>
Despite the hypothesis that the free word order of German leads to
poor performance of low order HMM taggers when compared with a
language like English, the overall results for German are very much
along the lines of comparable implementations for English, if not
better.  It can be argued that the disadvantage of free word order for
HMM taggers is compensated for by richer morphology and the
additional disambiguation cue of having upper and lower case initial
letters to distinguish POS membership. The latter, however, greatly
hinders the recognition of proper nouns, the most common type of
error, responsible for approximately <EQN/>
of the model's
<EQN/>
mistakes.
</P>
<P>
It is important to notice that the types of disambiguation carried out
by the tagger for German are significantly different from the
disambiguation work for English and French. While in English and
French a fair number of disambiguations involve separating major POS
classes such as verb, noun, and adjective, most of the work performed
in the German model involves disambiguation between subclasses of one
main category, such as finite vs. infinitive verb, noun vs. proper
noun, different sub-categories of pronouns, etc.
</P>
<P>
This finding has consequences for the COMPASS project, where POS
disambiguation is employed as one means of disambiguating word senses
to facilitate precise dictionary look-up. While this technique helps
to confine word senses for English and French, it is of little help for
word sense disambiguation in German.
</P>
<P>
However, the German model was useful for the project because a tagged
reference corpus was required for lexicographic work in order to adapt
existing bilingual dictionaries.  The tagger was used to annotate all
of the 50 million word German corpora contained on the ECI
Multilingual Corpus 1 CD-ROM.
</P>
</DIV>
<DIV ID="7" DEPTH="1" R-NO="7"><HEADER>  Acknowledgements </HEADER>
<P>
I would like to thank Helmut Schmid of the University of Stuttgart for
providing extensions of parameter initialization for the Xerox
Tagger and Jean-Pierre Chanod and Lauri Karttunen of the Rank Xerox
Research Laboratory Grenoble for making available the English and
French tagged texts and lexicons.  I would also like to acknowledge
valuable advice from Tracy Holloway King and Steven Abney, who
commented on earlier versions of this paper.
</P>
<P>
This work has been supported in part by the Ministry for Science and
Research of the Land Baden-Wrttemberg under the project ``Corpus
Based Development of Lexical Knowledge Bases (ELWIS)'' and by the
Commission of the European Community under the LRE project ``Adapting
Bilingual Dictionaries for Online Assistance (COMPASS, LRE 62-080)''.
</P>
<DIV ID="7.1" DEPTH="2" R-NO="1"><HEADER>Bibliography </HEADER>
<P>
Ted Briscoe, Greg Grefenstette, Llus Padr, and Iskander Serail.
1994.
Hybrid techniques for training HMM part-of-speech taggers.
Acquilex II working paper 45.
</P>
<P>
CELEX.
1993.
The CELEX Lexical Database. Dutch, English, German.
Max-Planck-Institute for Psycholinguistics, Centre for Lexical
  Information, Nijmegen.
CD-ROM.
</P>
<P>
Jean-Pierre Chanod and Pasi Tapanainen.
1994.
Statistical and constraint-based taggers for French.
Technical Report MLTT - 016, Rank Xerox Research Centre, Grenoble
  Laboratory, Grenoble.
</P>
<P>
Doung Cutting, Julian Kupiec, Jan Pedersen, and Penelope Sibun.
1992.
A practical part-of-speech tagger.
In Proceedings of the Third Conference on Applied Natural
  Language Processing, Trento.
</P>
<P>
ECI.
1994.
Multilingual Corpus 1.
Association for Computational Linguistics, European Corpus
  Intitiative.
CD-ROM.
</P>
<P>
David Elworthy.
1994.
Does Baum-Welch re-estimation help taggers?
In Proceedings of the Fourth Conference on Applied Natural
  Language Processing, Stuttgart, pages 53-58.
</P>
<P>
Helmut Feldweg.
1993.
Stochastische Wortartendisambiguierung fr das Deutsche:
  Untersuchungen mit dem robusten System LIKELY.
Technical report, Universitt Tbingen, Seminar fr
  Sprachwissenschaft.
</P>
<P>
Helmut Feldweg.
1995.
Stochastische Wortartendisambiguierung des Deutschen.
In Lexikon  Text, pages 241-254, Tbingen. Max Niemeyer.
forthcoming.
</P>
<P>
Julian Kupiec and Mike Wilkens.
1994.
The DDS tagger guide version 1.1.
Xerox Palo Alto Research Center, unpublished manuscript.
</P>
<P>
Bernard Merialdo.
1994.
Tagging English text with a probabilistic model.
Computational Linguistics, 20(2):155-171.
</P>
<P>
Helmut Schmid and Andr Kempe.
1995.
Tagging von Korpora mit HMM, Entscheidungsbumen und
  neuronalen Netzen.
In Helmut Feldweg and Erhard Hinrichs, editors, Lexikon 
  Text, Tbingen. Max Niemeyer.
forthcoming.
</P>
<P>
Christine Thielen and Manfred Sailer.
1994.
Ein Tagset frs Deutsche. Richtlinien fr die manuelle
  Wortarten-Annotierung von Textkorpora.
Seminar fr Sprachwissenschaft, Universitt Tbingen,
  unpublished Manuscript.
</P>
<P>
Christine Thielen and Anne Schiller.
1995.
Ein kleines und erweitertes Tagset frs Deutsche.
In Helmut Feldweg and Erhard Hinrichs, editors, Lexikon 
  Text, pages 215-226. Max Niemeyer, Tbingen.
forthcoming.
</P>
<P>
Christine Thielen.
1994.
Ein Tagset fr die Wortartenklassifizierung des Deutschen.
In Harald Trost, editor, KONVENS '94. sterreichische
  Gesellschaft fr Artificial Intelligence, Wien.
</P>
<P>
Klaus Wothke, Ilona Weck-Ulm, Johannes Heinecke, Oliver Mertineit, and Thomas
  Pachunke.
1993.
Statistically based automatic tagging of German text corpora with
  parts-of-speech -- some experiments.
Technical report, IBM Germany, Heidelberg Scientific Center,
  Heidelberg.
</P>
<P>
</P>
</DIV>
</DIV>
</BODY>
</MINIMAL-DOC>
