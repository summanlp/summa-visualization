<?xml version='1.0'?>
<!DOCTYPE MINIMAL-DOC SYSTEM "mini.dtd">
<MINIMAL-DOC>
<TITLE>OCCURRENCE VECTORS FROM CORPORA VS. DISTANCE VECTORS FROM DICTIONARIES</TITLE>
<ABSTRACT>
<P>
A comparison was made of vectors derived by using ordinary co-occurrence
statistics from large text corpora and
of vectors derived by measuring the inter-word distances in dictionary
definitions.
The precision of word sense disambiguation by
using co-occurrence vectors from the 1987 Wall Street Journal
(20M total words) was higher than that by using
distance vectors from the Collins English Dictionary
( head words +  definition words).
However, other experimental results suggest that distance vectors
contain some different semantic information from co-occurrence vectors.
</P>
</ABSTRACT>
<BODY>
<DIV ID="1" DEPTH="1" R-NO="1"><HEADER>  Introduction </HEADER>
<P>
Word vectors reflecting word meanings are expected to enable
numerical approaches to semantics.
Some early attempts at vector representation in psycholinguistics
 were the semantic differential approach <REF/>  and the associative distribution approach <REF/>. However, they were derived manually through psychological experiments.
An early attempt at automation was made by Wilks et al.
<REF/> using co-occurrence statistics.
Since then, there have been some promising results from using
co-occurrence vectors, such as word sense disambiguation
 <REF/>, and word clustering <REF/>. 
</P>
<P>
However, using the co-occurrence statistics requires a huge corpus
that covers even most rare words.
We recently developed word vectors that are derived from an ordinary
dictionary by measuring the inter-word distances in the word definitions
 <REF/>. This method, by its nature, has no problem handling rare words.
In this paper we examine the usefulness of these distance vectors
as semantic representations by comparing them with co-occurrence vectors.
</P>
</DIV>
<DIV ID="2" DEPTH="1" R-NO="2"><HEADER>  Distance Vectors </HEADER>
<P>
A reference network of the words in a dictionary (Fig. )
is used to measure the distance between words.
The network is a graph that shows which words are used in
 the definition of each word <REF/>. The network shown in Fig. is for a very small portion
of the reference network for the Collins English Dictionary
 (1979 edition) in the CD-ROM I <REF/>, with  head words +  definition words.
</P>
<IMAGE TYPE="FIGURE"/>
<P>
For example, the definition for dictionary is ``a book in which the
words of a language are listed alphabetically ... .''
The word dictionary is thus linked to the words
book, word, language, and alphabetical.
</P>
<P>
A word vector is defined as the list of distances from a word to a
certain set of selected words, which we call origins.
The words in Fig. marked with Oi (unit, book,
and people) are assumed to be origin words.
In principle, origin words can be freely chosen.
In our experiments we used middle frequency words:
the 51st to 1050th most frequent words
in the reference Collins English Dictionary (CED).
</P>
<P>
The distance vector for dictionary is derived as follows:
</P>
<P>
<!-- MATH: \begin{equation}
\end{equation} -->
</P>
<IMAGE TYPE="TABLE"/>
<IMAGE TYPE="TABLE"/>
<P>
The i-th element is the
distance (the length of the shortest path) between dictionary and
the i-th origin, Oi.
To begin, we assume every link has a constant length of 1.
The actual definition for link length will be given later.
</P>
<P>
If word A is used in the definition of word B, these words are expected
to be strongly related.
This is the basis of our hypothesis that the distances in the reference
network reflect the associative distances between words
 <REF/>. 
</P>
<P>
Use of Reference Networks 
Reference networks have been successfully used as
neural networks (by Vronis and Ide <REF/>
for word sense disambiguation)
and as fields for artificial association, such as spreading activation
(by Kojima and Furugori <REF/> for
context-coherence measurement).
The distance vector of a word can be considered to be a list of the
activation strengths at the origin nodes when the word node is activated.
Therefore, distance vectors can be expected to convey almost the same
information as the entire network, and clearly they are much easier
to handle.
</P>
<P>
Dependence on Dictionaries 
As a semantic representation of words, distance vectors are expected to
depend very weakly on the particular source dictionary.
We compared two sets of distance vectors,
 one from LDOCE <REF/> and the other from  COBUILD <REF/>, and verified that their difference is at least smaller than the difference of
 the word definitions themselves <REF/>. 
</P>
<P>
We will now describe some technical details about the derivation
of distance vectors.
</P>
<P>
Link Length 
Distance measurement in a reference network depends on the
definition of link length.
Previously, we assumed for simplicity that every link
has a constant length.
However, this simple definition seems unnatural because it does not
reflect word frequency.
Because a path through low-frequency words (rare words) implies
a strong relation, it should be measured as a shorter path.
Therefore, we use the following definition of link length,
which takes account of word frequency.
</P>
<IMAGE TYPE="FIGURE"/>
<P>
This shows the length of the links between words W
<!-- MATH: $_i (i=1,2)$ -->
i (i=1,2)in Fig.,
where Ni denotes the total number of links from and to Wiand n denotes the number of direct links between these two words.
</P>
<IMAGE TYPE="FIGURE"/>
<P>
Normalization 
Distance vectors are normalized by first
changing each coordinate into its deviation in the coordinate:
</P>
<IMAGE TYPE="FIGURE"/>
<P>
where ai and 
</P>
<IMAGE TYPE="FIGURE"/>
<P>
are the average and the standard deviation
of the distances from the i-th origin.
Next, each coordinate is changed into its deviation in the vector:
</P>
<IMAGE TYPE="FIGURE"/>
<P>
where 
<!-- MATH: $\overline{v'}$ -->
</P>
<IMAGE TYPE="FIGURE"/>
<P>
and 
</P>
<IMAGE TYPE="FIGURE"/>
<P>
are the average and the standard
deviation of 
<!-- MATH: $v'_i\; \hbox{\small\((i=1,...)\) }$ -->
</P>
<IMAGE TYPE="FIGURE"/>
<P>
 .
</P>
</DIV>
<DIV ID="3" DEPTH="1" R-NO="3"><HEADER>  Co-occurrence Vectors </HEADER>
<P>
We use ordinary co-occurrence statistics and
measure the co-occurrence likelihood between two words, X and Y,
 by the mutual information estimate <REF/>: 
</P>
<IMAGE TYPE="FIGURE"/>
<P>
where 
</P>
<IMAGE TYPE="FIGURE"/>
<P>
is the occurrence density of word X in a whole corpus,
and the conditional probability 
<!-- MATH: $\rm P(X\,|\,Y)$ -->
</P>
<IMAGE TYPE="FIGURE"/>
<P>
is the density of X
in a neighborhood of word Y.
Here the neighborhood is defined as 50 words before or after any
appearance of word Y.
(There is a variety of neighborhood definitions such as
 ``100 surrounding words'' <REF/> and ``within a distance of no more than 3 words ignoring function words''
 <REF/>.) 
</P>
<P>
The logarithm with `+' is defined to be 0 for an argument less than 1.
Negative estimates were neglected because they are mostly accidental
 except when X and Y are frequent enough <REF/>. 
</P>
<P>
A co-occurence vector of a word is defined as the list of co-occurrence
likelihood of the word with a certain set of origin words.
We used the same set of origin words as for the distance vectors.
</P>
<IMAGE TYPE="FIGURE"/>
<P>
Co-occurrence Vector.
</P>
<P>
When the frequency of X or Y is zero, we can not measure their
co-occurence likelihood, and such cases are not exceptional.
This sparseness problem is well-known and serious in the co-occurrence
statistics.
We used as a corpus the 1987 Wall Street Journal in the CD-ROM I
ACL-CD-ROM-1, which has a total of 20M words.
The number of words which appeared at least once was about 50%
of the total 62K head words of CED, and the percentage of
the word-origin pairs which appeared at least once was
about 16% of total 62K 
</P>
<IMAGE TYPE="FIGURE"/>
<P>
  1K (=62M) pairs.
When the co-occurrence likelihood can not be measured,
the value 
<!-- MATH: $\rm I(X,Y)$ -->
</P>
<IMAGE TYPE="FIGURE"/>
<P>
  was set to 0.
</P>
</DIV>
<DIV ID="4" DEPTH="1" R-NO="4"><HEADER>  Experimental Results </HEADER>
<P>
We compared the two vector representations by using them for
the following two semantic tasks.
The first is word sense disambiguation (WSD) based on the similarity of
context vectors;
the second is the learning of  or  meanings
from example words.
</P>
<P>
With WSD, the precision by using co-occurrence vectors
from a 20M words corpus was higher than by using distance vectors
from the CED.
</P>
<DIV ID="4.1" DEPTH="2" R-NO="1"><HEADER>  Word Sense Disambiguation </HEADER>
<P>
Word sense disambiguation is a serious semantic problem.
A variety of approaches have been proposed for solving it.
For example, Vronis and Ide <REF/>
used reference networks as neural networks,
Hearst <REF/> used (shallow) syntactic similarity
between contexts,
Cowie et al. <REF/> used simulated
annealing for quick parallel disambiguation, and
Yarowsky <REF/> used co-occurrence statistics
between words and thesaurus categories.
</P>
<P>
Our disambiguation method is based on the similarity of context vectors,
which was originated by Wilks et al. <REF/>.
In this method, a context vector is the sum of its constituent word
vectors (except the target word itself).
That is, the context vector for context,
</P>
<IMAGE TYPE="FIGURE"/>
<P>
is
</P>
<IMAGE TYPE="FIGURE"/>
<P>
The similarity of contexts is measured by the angle of their vectors
(or actually the inner product of their normalized vectors).
</P>
<IMAGE TYPE="FIGURE"/>
<P>
Let word 
</P>
<IMAGE TYPE="FIGURE"/>
<P>
  have senses 
<!-- MATH: $\rm s_1, s_2, ..., s_m$ -->
</P>
<IMAGE TYPE="FIGURE"/>
<P>
 , and
each sense have the following context examples.
</P>
<IMAGE TYPE="FIGURE"/>
<P>
We infer that the sense of word 
</P>
<IMAGE TYPE="FIGURE"/>
<P>
  in an arbitrary context 
</P>
<IMAGE TYPE="FIGURE"/>
<P>
 is 
</P>
<IMAGE TYPE="FIGURE"/>
<P>
  if for some j the similarity, 
<!-- MATH: $\rm sim(C,C_{i\,j})$ -->
</P>
<IMAGE TYPE="FIGURE"/>
<P>
 ,
is maximum among all the context examples.
</P>
<P>
Another possible way to infer the sense is to choose sense 
</P>
<IMAGE TYPE="FIGURE"/>
<P>
 such that the average of 
<!-- MATH: $\rm sim(C,C_{i\,j})$ -->
</P>
<IMAGE TYPE="FIGURE"/>
<P>
  over
<!-- MATH: $\rm j\,=\,1,2,...,n_i$ -->
</P>
<IMAGE TYPE="FIGURE"/>
<P>
  is maximum.
We selected the first method because a peculiarly similar example is more
important than the average similarity.
</P>
<P>
Figure  (next page) shows the disambiguation precision
for 9 words.
For each word, we selected two senses shown over each graph.
These senses were chosen because they are clearly different and
we could collect sufficient number (more than 20) of context examples.
The names of senses were chosen from the category names in
Roget's International Thesaurus, except organ's.
</P>
<P>
The results using distance vectors are shown by dots
(
</P>
<IMAGE TYPE="FIGURE"/>
<IMAGE TYPE="FIGURE"/>
<IMAGE TYPE="FIGURE"/>
<P>
 ),
and using co-occurrence vectors from the 1987 WSJ (20M words)
by circles (  ).
</P>
<P>
A context size (x-axis) of, for example, 10 means 10 words before the
target word and 10 words after the target word.
We used 20 examples per sense; they were taken from the 1988 WSJ.
The test contexts were from the 1987 WSJ:
The number of test contexts varies from word to word (100 to 1000).
The precision is the simple average of the respective precisions for
the two senses.
</P>
<P>
The results of Fig. show that the precision by
using co-occurrence vectors are higher than that by using distance
vectors except two cases, interest and customs.
And we have not yet found a case where the distance vectors give higher
precision. Therefore we conclude that co-occurrence vectors are
advantageous over distance vectors to WSD based on the context similarity.
</P>
<P>
The sparseness problem for co-occurrence vectors is not serious in this
case because each context consists of plural words.
</P>
</DIV>
<DIV ID="4.2" DEPTH="2" R-NO="2"><HEADER>  Learning of -or- </HEADER>
<P>
Another experiment using the same two vector representations
was done to measure the learning of  or  meanings.
Figure  shows the changes in the precision
(the percentage of agreement with the authors' combined judgement).
The x-axis indicates the number of example words for each
 or  pair.
Judgement was again done by using the nearest example.
The example and test words are shown in Tables  and
, respectively.
</P>
<IMAGE TYPE="FIGURE"/>
<P>
In this case, the distance vectors were advantageous.
The precision by using distance vectors increased to about 80% and then
leveled off,
while the precision by using co-occurrence vectors stayed around 60%.
We can therefore conclude that the property of -or- is
reflected in distance vectors more strongly than in co-occurrence vectors.
The sparseness problem is supposed to be a major factor in this case.
</P>
<IMAGE TYPE="FIGURE"/>
</DIV>
<DIV ID="4.3" DEPTH="2" R-NO="3"><HEADER>  Supplementary Data </HEADER>
<P>
In the experiments discussed above, the corpus size for co-occurrence
vectors was set to 20M words ('87 WSJ)
and the vector dimension for both co-occurrence and distance vectors was
set to 1000.
Here we show some supplementary data that support these parameter
settings.
</P>
<P>
a. Corpus size (for co-occurrence vectors)
</P>
<P>
Figure  shows the change in disambiguation precision
as the corpus size for co-occurrence statistics increases from 200
words to 20M words.
(The words are suit, issue and race,
the context size is 10,
and the number of examples per sense is 10.)
These three graphs level off after around 1M words.
Therefore, a corpus size of 20M words is not too small.
</P>
<IMAGE TYPE="FIGURE"/>
<P>
b. Vector Dimension
</P>
<P>
Figure  (next page) shows the dependence of disambiguation
precision on the vector dimension for (i) co-occurrence and
(ii) distance vectors.
As for co-occurrence vectors, the precision levels off near a dimension
of 100. Therefore, a dimension size of 1000 is sufficient or even
redundant.
However, in the distance vector's case, it is not clear whether
the precision is leveling or still increasing around 1000 dimension.
</P>
</DIV>
</DIV>
<DIV ID="5" DEPTH="1" R-NO="5"><HEADER>  Conclusion </HEADER>
<P>
<ITEMIZE>
<ITEM>
A comparison was made of co-occurrence vectors from large text corpora
and of distance vectors from dictionary definitions.
</ITEM>
<ITEM>
For the word sense disambiguation based on the context similarity,
co-occurrence vectors from the 1987 Wall Street Journal (20M total words)
was advantageous over distance vectors from the Collins English Dictionary
( head words +  definition words).
</ITEM>
<ITEM>
For learning  or  meanings from example words,
distance vectors gave remarkably higher precision than co-occurrence
vectors.
This suggests, though further investigation is required, that distance
vectors contain some different semantic information from
co-occurrence vectors.
</ITEM>
</ITEMIZE>
</P>
<IMAGE TYPE="FIGURE"/>
<DIV ID="5.1" DEPTH="2" R-NO="1"><HEADER>Bibliography </HEADER>
<P>
Kenneth W. Church and Patrick Hanks.
1989.
Word association norms, mutual information, and lexicography.
In Proceedings of the 27th Annual Meeting of the Association
for Computational Linguistics, pages 76-83, Vancouver, Canada.
</P>
<P>
Jim Cowie, Joe Guthrie, and Louise Guthrie.
1992.
Lexical disambiguation using simulated annealing.
In Proceedings of COLING-92, pages 359-365, Nantes, France.
</P>
<P>
Ido Dagan, Shaul Marcus, and Shaul Markovitch.
1993.
Contextual word similarity and estimation from sparse data.
In Proceedings of the 31st Annual Meeting of the Association
for Computational Linguistics, pages 164-171, Columbus, Ohio.
</P>
<P>
James Deese.
1962.
On the structure of associative meaning.
Psychological Review, 69(3):161-175.
</P>
<P>
Marti A. Hearst.
1991.
Noun homograph disambiguation using local context in large text
  corpora.
In Proceedings of the 7th Annual Conference of the University of
  Waterloo Center for the New OED and Text Research, pages 1-22, Oxford.
</P>
<P>
Hideki Kozima and Teiji Furugori.
1993.
Similarity between words computed by spreading activation on an
  english dictionary.
In Proceedings of EACL-93, pages 232-239, Utrecht, the
  Netherlands.
</P>
<P>
Mark Liberman, editor.
1991.
CD-ROM I.
Association for Computational Linguistics Data Collection Initiative,
  University of Pennsylvania.
</P>
<P>
Yoshihiko Nitta.
1988.
The referential structure of the word definitions in ordinary
  dictionaries.
In Proceedings of the Workshop on the Aspects of Lexicon for
  Natural Language Processing, LNL88-8, JSSST, pages 1-21, Fukuoka
  University, Japan.
(in Japanese).
</P>
<P>
Yoshihiko Nitta.
1993.
Referential structure - a mechanism for giving word-definition in
  ordinary lexicons.
In C. Lee and B. Kang, editors, Language, Information and
  Computation, pages 99-110. Thaehaksa, Seoul.
</P>
<P>
Yoshiki Niwa and Yoshihiko Nitta.
1993.
Distance vector representation of words, derived from reference
  networks in ordinary dictionaries.
MCCS 93-253, Computing Research Laboratory, New Mexico State
  University, Las Cruces.
</P>
<P>
C. E. Osgood, G. F. Such, and P. H. Tannenbaum.
1957.
The Measurement of Meaning.
University of Illinois Press, Urbana.
</P>
<P>
Fernando Pereira, Naftali Tishby, and Lillian Lee.
1993.
Distributional clustering of english words.
In Proceedings of the 31st Annual Meeting of the Association for
  Computational Linguistics, pages 183-190, Columbus, Ohio.
</P>
<P>
Paul Procter, editor.
1978.
Longman Dictionary of Contemporary English (LDOCE).
Longman, Harlow, Essex, first edition.
</P>
<P>
Hinrich Schtze.
1993.
Word space.
In J. D. Cowan S. J. Hanson and C. L. Giles, editors, Advances
  in Neural Information Processing Systems, pages 895-902. Morgan Kaufmann,
  San Mateo, California.
</P>
<P>
John Sinclair, editor.
1987.
Collins COBUILD English Language Dictionary.
Collins and the University of Birmingham, London.
</P>
<P>
Jean Vronis and Nancy M. Ide.
1990.
Word sense disambiguation with very large neural networks extracted
  from machine readable dictionaries.
In Proceedings of COLING-90, pages 389-394, Helsinki.
</P>
<P>
Yorick Wilks, Dan Fass, Cheng ming Guo, James E. McDonald, Tony Plate, and
  Brian M. Slator.
1990.
Providing machine tractable dictionary tools.
Machine Translation, 5(2):99-154.
</P>
<P>
David Yarowsky.
1992.
Word-sense disambiguation using statistical models of roget's
  categories trained on large corpora.
In Proceedings of COLING-92, pages 454-460, Nantes, France.
</P>
</DIV>
</DIV>
</BODY>
</MINIMAL-DOC>
