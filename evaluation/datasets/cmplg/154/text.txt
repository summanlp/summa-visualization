
It is widely acknowledged that a full account of natural language
utterances cannot be given in terms of only syntactic or semantic
phenomena. For example, Hirschberg  has shown
that in order to understand a scalar implicature, one must analyze the
conversants' beliefs and intentions. To recognize normal state
implicatures one must consider mutual beliefs and
 plans . To understand conversational implicatures associated with indirect replies one must consider discourse
expectations, discourse plans, and discourse
 relations ,. Some presuppositions are inferrable when certain lexical constructs (factives, aspectuals, etc) or
syntactic constructs (cleft and pseudo-cleft sentences) are used.
Despite all the complexities that individualize the recognition stage
for each of these inferences, all of them can be defeated by
context, by knowledge, beliefs, or plans of the agents that constitute
part of the context, or by other pragmatic rules.

Defeasibility is a notion that is tricky to deal with, and
scholars in logics and pragmatics have learned to circumvent it or
live with it. The first observers of the phenomenon preferred to keep
defeasibility outside the mathematical world. For
Frege , Russell , and
Quine  ``everything exists''; therefore, in their
logical systems, it is impossible to formalize the cancellation of the
presupposition that definite referents
 exist ,. We can taxonomize previous approaches to defeasible pragmatic inferences into three categories
(we omit here work on defeasibility related to linguistic phenomena
such as discourse, anaphora, or speech acts).

1.  Most linguistic approaches account for the defeasibility of
  pragmatic inferences by analyzing them in a context that consists of
  all or some of the previous utterances, including the current one.
   Context ,, procedural    rules ,, lexical and syntactic    structure , intentions , or    anaphoric constraints , decide what   presuppositions or implicatures are projected as pragmatic
  inferences for the utterance that is analyzed. The problem with
  these approaches is that they assign a dual life to pragmatic
  inferences: in the initial stage, as members of a simple or complex
  utterance, they are defeasible.  However, after that utterance is
  analyzed, there is no possibility left of cancelling that inference.
  But it is natural to have implicatures and presuppositions that are
  inferred and cancelled as a sequence of utterances proceeds:
   research in conversation repairs  abounds in such   examples. We address this issue in more detail in
   section . 

2. One way of accounting for cancellations that occur later in the
  analyzed text is simply to extend the boundaries within which
  pragmatic inferences are evaluated, i.e., to look ahead a few
  utterances. Green  assumes that implicatures are
  connected to discourse entities and not to utterances, but her
  approach still does not allow cancellations across discourse units.

3.  Another way of allowing pragmatic inferences to be cancelled is
  to assign them the status of defeasible information.
  Mercer mercerphd formalizes presuppositions in a logical
   framework that handles defaults , but this approach   is not tractable and it treats natural disjunction as an
  exclusive-or and implication as logical equivalence.

Computational approaches fail to account for the cancellation of
 pragmatic inferences: once presuppositions  or  implicatures , are generated, they can never be cancelled. We are not aware of any formalism or computational
approach that offers a unified explanation for the cancellability of
pragmatic inferences in general, and of no approach that handles
cancellations that occur in sequences of utterances.

It is our aim to provide such an approach here.  In doing this, we
assume the existence, for each type of pragmatic inference, of a set of
necessary conditions that must be true in order for that inference to
be triggered. Once such a set of conditions is met, the corresponding
inference is drawn, but it is assigned a defeasible status. It is the
role of context and knowledge of the conversants to ``decide'' whether
that inference will survive or not as a pragmatic inference of the
structure.  We put no boundaries upon the time when such a
cancellation can occur, and we offer a unified explanation for
pragmatic inferences that are inferable when simple utterances,
complex utterances, or sequences of utterances are considered.

We propose a new formalism, called ``stratified logic'', that correctly
handles the pragmatic inferences, and we start by giving a very brief
introduction to the main ideas that underlie it.  We give the main
steps of the algorithm that is defined on the backbone of stratified
logic. We then show how different classes of pragmatic inferences can
be captured using this formalism, and how our algorithm computes the
expected results for a representative class of pragmatic inferences.
The results we report here are obtained using an implementation
 written in Common Lisp that uses Screamer , a macro package that provides nondeterministic constructs.

We can offer here only a brief overview of stratified logic. The
reader is referred to Marcu  for a
comprehensive study. Stratified logic supports one type of
indefeasible information and two types of defeasible information,
namely, infelicitously defeasible and felicitously defeasible.  The
notion of infelicitously defeasible information is meant to capture
inferences that are anomalous to cancel, as in:
(1) 
* John regrets that Mary came to the party but she did not
 come. The notion of felicitously defeasible information is meant to capture the inferences that can be cancelled without any abnormality, as in:
(2) 
John does not regret that Mary came to the party because she
 did not come.  

 The lattice in figure  underlies the semantics of stratified logic.  The lattice depicts the three levels of strength
that seem to account for the inferences that pertain to natural
language semantics and pragmatics: indefeasible information belongs to
the u layer, infelicitously defeasible information belongs to the
i layer, and felicitously defeasible information belongs to the dlayer. Each layer is partitioned according to its polarity in truth,

,
and falsity, 

.
The lattice
shows a partial order that is defined over the different levels of
truth. For example, something that is indefeasibly false, ,
is
stronger (in a sense to be defined below) than something that is
infelicitously defeasibly true, ,
or felicitously defeasibly
false, .
Formally, we say that the u level is stronger than
the i level, which is stronger than the d level: 

.

At the syntactic level, we allow atomic formulas to be labelled
according to the same underlying lattice. Compound formulas are
obtained in the usual way. This will give us formulas
such as 

,
or 

.
The satisfaction relation is split
according to the three levels of truth into u-satisfaction,
i-satisfaction, and d-satisfaction:

    Assume 
is an  
valuation such that 


and assume that 
maps n-ary predicates
p to relations 

.
For any atomic formula 

,
and any stratified
valuation ,
where 


and
ti are terms, the x-satisfiability relations are
defined as follows:





iff 






iff   






iff   






iff 






iff 






iff   






iff 






iff 






iff 





 Definition  extends in a natural way to negated and compound formulas. Having a satisfaction definition associated with
each level of strength provides a high degree of flexibility. The same
theory can be interpreted from a perspective that allows more
freedom (u-satisfaction), or from a perspective that is tighter
and that signals when some defeasible information has been cancelled (i-
and d-satisfaction).

Possible interpretations of a given set of utterances with respect to
a knowledge base are computed using an extension of the semantic
tableau method. This extension has been proved to be both sound and
 complete . A partial ordering, , determines
the set of optimistic interpretations for a theory.  An
interpretation m0 is preferred to, or is more optimistic than, an
interpretation m1 (

)
if it contains more information
and that information can be more easily updated in the future.  That means
that if an interpretation m0 makes an utterance true by assigning
to a relation R a defeasible status, while another interpretation
m1 makes the same utterance true by assigning the same relation Ra stronger status, m0 will be the preferred or optimistic
one, because it is as informative as m1 and it allows more options
in the future (R can be defeated).

Pragmatic inferences are triggered by utterances. To differentiate
between them and semantic inferences, we introduce a new quantifier,

,
whose semantics is defined such that a pragmatic inference
of the form 


is instantiated only for those objects from the universe of discourse that pertain to an utterance having the
form 

.
Hence, only if the antecedent of a
pragmatic rule has been uttered can that rule be applied. A
meta-logical construct uttered applies to the logical translation of
utterances.  This theory yields the following definition:

    Let 
be a theory described in terms of stratified first-order
logic that appropriately formalizes the semantics of lexical items and
the necessary conditions that trigger pragmatic inferences. The
semantics of lexical terms is formalized using the quantifier
,
while the necessary conditions that pertain to pragmatic
inferences are captured using 

.
Let 

uttered(u) be the
logical translation of a given utterance or set of utterances. We say
that utterance u 


p if and only
if p[d] or p[i] is derived using pragmatic inferences in at least
one optimistic model of the theory 

,
and if pis not cancelled by any stronger information (

)
in any optimistic model schema of the
theory. Symmetrically, one can define what a negative pragmatic
inference is.  In both cases, 


is u-consistent.

Our algorithm, described in detail by
Marcu , takes as input a set of
first-order stratified formulas 
that represents an adequate
knowledge base that expresses semantic knowledge and the necessary
conditions for triggering pragmatic inferences, and the translation of
an utterance or set of utterances 

uttered(u). The algorithm builds
the set of all possible interpretations for a given utterance, using a
generalization of the semantic tableau technique.  The model-ordering
relation filters the optimistic interpretations. Among them, the
defeasible inferences that have been triggered on pragmatic grounds
are checked to see whether or not they are cancelled in any optimistic
interpretation.  Those that are not cancelled are labelled as
pragmatic inferences for the given utterance or set of utterances.

We present a set of examples that covers a representative group of
pragmatic inferences. In contrast with most other approaches, we
provide a consistent methodology for computing these inferences and
for determining whether they are cancelled or not for all possible
configurations: simple and complex utterances and sequences of
utterances.

A factive such as the verb regret presupposes its complement, but
as we have seen, in positive environments, the presupposition is
stronger: it is
acceptable to defeat a presupposition triggered in a negative
 environment (), but is infelicitous to defeat  one that belongs to a positive environment ().  Therefore, an appropriate formalization of utterance ()  and the requisite pragmatic knowledge will be as shown in (). 
(3) 
 John does not regret that Mary came to the party.  
(4) 



The stratified semantic tableau that corresponds to
 theory () is given in figure . The tableau yields two model schemata (see
 figure ); in both of them, it is defeasibly inferred that Mary came to the party. The model-ordering
relation 
establishes m0 as the optimistic model for the
theory because it contains as much information as m1 and is easier
to defeat. Model m0 explains why Mary came to the party is a
 presupposition for utterance (). 

 Consider utterance (), and its  implicatures (). 
(5) 
John says that some of the boys went to the theatre.
(6) 
Not {many/most/all} of the boys went to the theatre.
 An appropriate formalization is given in (   ), where the second formula captures the defeasible scalar
implicatures and the third formula reflects the relevant semantic
information for all.
(7) 


 The theory provides one optimistic model schema (figure    ) that reflects the expected pragmatic inferences, i.e., (Not most/Not
many/Not all) of the boys went to the theatre.

Assume now, that after a moment of thought, the same person utters:
(8) 
 John says that some of the boys went to the theatre. In fact
all of them went to the theatre.By adding the extra utterance to the initial
 theory (),  
uttered(went(all(boys), theatre)), one
would obtain one optimistic model schema in which the conventional
 implicatures have been cancelled (see figure ). 

The Achilles heel for most theories of presupposition  has been their
vulnerability to the projection problem.  Our solution for the
projection problem does not differ from a solution for individual
utterances. Consider the following utterances and some of their
 associated presuppositions () (the symbol  precedes
an inference drawn on pragmatic grounds):
(9) 
Either Chris is not a bachelor or he regrets that Mary came
 to the party.  
(10) 
 Chris is a bachelor or a spinster.  
(11) 

 Chris is a (male) adult. Chris is not a bachelor presupposes that Chris is a male adult; Chris regrets that Mary came to the party presupposes
that Mary came to the party. There is no contradiction between
these two presuppositions, so one would expect a conversant to infer
both of them if she hears an utterance such
 as (). However, when one examines  utterance (), one observes immediately that there is a contradiction between the presuppositions carried by the individual
components. Being a bachelor presupposes that Chris is a male,
while being a spinster presupposes that Chris is a
female. Normally, we would expect a conversant to notice this
contradiction and to drop each of these elementary presuppositions
 when she interprets (). 

We now study how stratified logic and  the model-ordering
relation capture one's intuitions.

 An appropriate formalization for utterance () and the  necessary semantic and pragmatic knowledge is given in (). 
(12) 


 Besides the translation of the utterance, the initial theory contains a formalization of the defeasible implicature that natural disjunction
is used as an exclusive or, the knowledge that Mary is not
a name for males, the lexical semantics for the word
bachelor, and the lexical pragmatics for bachelor and regret.  The stratified semantic tableau generates 12 model
schemata. Only four of them are kept as optimistic models for the
utterance.  The models yield Mary came to the party; Chris is a
male; and Chris is an adult as pragmatic inferences of
 utterance (). 

 Consider now utterance ().  The stratified semantic tableau that corresponds to its logical theory yields 16 models, but
only Chris is an adult satisfies
 definition  and is projected as presupposition for the utterance.

We have already mentioned that speech repairs constitute a good
benchmark for studying the generation and cancellation of pragmatic
 inferences along sequences of utterances .  Suppose, for example, that Jane has two friends -- John Smith and John Pevler --
and that her roommate Mary has met only John Smith, a married fellow.
Assume now that Jane has a conversation with Mary in which Jane
mentions only the name John because she is not aware that Mary does
not know about the other John, who is a five-year-old boy. In this
context, it is natural for Mary to become confused and to come to wrong
conclusions. For example, Mary may reply that John is not a
  bachelor. Although this is true for both Johns, it is more
appropriate for the married fellow than for the five-year-old boy.
Mary knows that John Smith is a married male, so the utterance makes
sense for her. At this point Jane realizes that Mary misunderstands
her: all the time Jane was talking about John Pevler, the
 five-year-old boy. The utterances in () constitute a possible answer that Jane may give to Mary in order to clarify the problem.
(13) 
 a. No, John is not a bachelor. 
b. I regret that you have misunderstood me. 
 c. He is only five years old. The first utterance in the sequence presupposes (   ). 
(14) 
 
John is a male adult.
 )b warns Mary that is very likely she misunderstood a  previous utterance (   ). The warning is conveyed by implicature.
(15) 
 
 The hearer misunderstood the speaker. At this point, the hearer, Mary, starts to believe that one of her previous utterances has been elaborated on a
false assumption, but she does not know which one. The third
 utterance ()c comes to clarify the issue. It explicitly expresses that John is not an adult. Therefore, it
 cancels the early presupposition (): 
(16) 


John is an adult.
 Note that there is a gap of one statement between the generation and the cancellation of this presupposition. The behavior described is
mirrored both by our theory and our program.

The same methodology can be applied to modeling conversational
 implicatures in indirect replies . Green's algorithm makes use of discourse expectations, discourse plans, and discourse
 relations. The following dialog is considered , p. 68]: 
(17) 
Q:   Did you go shopping? 
A: a. My car's not running. 
              b. The timing belt broke. 
               c. (So) I had to take the bus.  

 Answer () conveys a ``yes'', but a reply  consisting  only of ()a would implicate a ``no''. As Green notices,  in previous models of implicatures ,,  processing ()a will block the implicature generated  by ()c. Green solves the problem by extending the boundaries of the analysis to discourse units. Our approach does not
exhibit these constraints. As in the previous example, the one dealing
with a sequence of utterances, we obtain a different interpretation
after each step. When the question is asked, there is no
 conversational implicature. Answer ()a makes the necessary conditions for implicating ``no'' true, and the implication
 is computed. Answer ()b reinforces a previous condition.  Answer ()c makes the preconditions for implicating a ``no'' false, and the preconditions for implicating a ``yes'' true.
Therefore, the implicature at the end of the dialogue is that the
conversant who answered went shopping.

Unlike most research in pragmatics that focuses on certain types of
presuppositions or implicatures, we provide a global framework in
which one can express all these types of pragmatic inferences. Each
pragmatic inference is associated with a set of necessary conditions
that may trigger that inference.  When such a set of conditions is
met, that inference is drawn, but it is assigned a defeasible status.
An extended definition of satisfaction and a notion of ``optimism''
with respect to different interpretations yield the preferred
interpretations for an utterance or sequences of utterances. These
interpretations contain the pragmatic inferences that have not been
cancelled by context or conversant's knowledge, plans, or intentions.
The formalism yields an algorithm that has been implemented in Common
Lisp with Screamer. This algorithm computes uniformly pragmatic
inferences that are associated with simple and complex utterances and
sequences of utterances, and allows cancellations of pragmatic
inferences to occur at any time in the discourse.

Acknowledgements

This research was supported in part by a grant from the Natural
Sciences and Engineering Research Council of Canada.

G. Frege.
1892.
ber sinn und bedeutung.
Zeitschrift fr Philos. und Philos. Kritik, 100:373-394.
reprinted as: On Sense and Nominatum, In Feigl H. and Sellars W.,
  editors, Readings in Philosophical Analysis, pages 85-102,
  Appleton-Century-Croft, New York, 1947.

G.J.M. Gazdar.
1979.
Pragmatics: Implicature, Presupposition, and Logical Form.
Academic Press.

N. Green and S. Carberry.
1994.
A hybrid reasoning model for indirect answers.
In Proceedings 32nd Annual Meeting of the Association for
  Computational Linguistics, pages 58-65.

N. Green.
1990.
Normal state implicature.
In Proceedings 28th Annual Meeting of the Association for
  Computational Linguistics, pages 89-96.

N. Green.
1992.
Conversational implicatures in indirect replies.
In Proceedings 30th Annual Meeting of the Association for
  Computational Linguistics, pages 64-71.

J.B. Hirschberg.
1985.
A theory of scalar implicature.
Technical Report MS-CIS-85-56, Department of Computer and Information
  Science, University of Pennsylvania.
Also published by Garland Publishing Inc., 1991.

G. Hirst, S. McRoy, P. Heeman, P. Edmonds, and D. Horton.
1994.
Repairing conversational misunderstandings and non-understandings.
Speech Communication, 15:213-229.

G. Hirst.
1991.
Existence assumptions in knowledge representation.
Artificial Intelligence, 49:199-242.

L. Karttunen and S. Peters.
1979.
Conventional implicature.
In Oh C.K. and Dinneen D.A, editors, Syntax and Semantics,
  Presupposition, volume 11, pages 1-56. Academic Press.

L. Karttunen.
1974.
Presupposition and linguistic context.
Theoretical Linguistics, 1:3-44.

P. Kay.
1992.
The inheritance of presuppositions.
Linguistics  Philosophy, 15:333-379.

D. Marcu.
1994.
A formalism and an algorithm for computing pragmatic inferences and
  detecting infelicities.
Master's thesis, Dept. of Computer Science, University of Toronto,
  September.
Also published as Technical Report CSRI-309, Computer Systems
  Research Institute, University of Toronto.

D. Marcu and G. Hirst.
1994.
An implemented formalism for computing linguistic presuppositions and
  existential commitments.
In H. Bunt, R. Muskens, and G. Rentier, editors, International
  Workshop on Computational Semantics, pages 141-150, December.

S. McRoy and G. Hirst.
1993.
Abductive explanation of dialogue misunderstandings.
In Proceedings, 6th Conference of the European Chapter of the
  Association for Computational Linguistics, pages 277-286, April.

R.E. Mercer.
1987.
A Default Logic Approach to the Derivation of Natural Language
  Presuppositions.
Ph.D. thesis, Department of Computer Science, University of British
  Columbia.

W.V.O. Quine.
1949.
Designation and existence.
In Feigl H. and Sellars W., editors, Readings in Philosophical
  Analysis, pages 44-51. Appleton-Century-Croft, New York.

R. Reiter.
1980.
A logic for default reasoning.
Artificial Intelligence, 13:81-132.

B. Russell.
1905.
On denoting.
Mind n.s., 14:479-493.
reprinted in: Feigl H. and Sellars W. editors, Readings in
  Philosophical Analysis, pages 103-115. Appleton-Century-Croft, New York,
  1949.

R.A. van der Sandt.
1992.
Presupposition projection as anaphora resolution.
Journal of Semantics, 9:333-377.

J.M. Siskind and D.A. McAllester.
1993.
Screamer: A portable efficient implementation of nondeterministic
  Common Lisp.
Technical Report IRCS-93-03, University of Pennsylvania, Institute
  for Research in Cognitive Science, July 1.

R.M. Weischedel.
1979.
A new semantic computation while parsing: Presupposition and
  entailment.
In Oh C.K. and Dinneen D.A, editors, Syntax and Semantics,
  Presupposition, volume 11, pages 155-182. Academic Press.

H. Zeevat.
1992.
Presupposition and accommodation in update semantics.
Journal of Semantics, 9:379-412.

