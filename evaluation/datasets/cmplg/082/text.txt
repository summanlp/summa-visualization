
Although a universal feature theory does not exist, there is
a general understanding of its objects. The objects of feature
theories are abstract linguistic objects, e.g., an object ``sentence,''
an object ``masculine third person singular,'' an object ``verb,'' an
object ``noun phrase.'' These abstract objects have properties like
``tense,'' ``number,'' ``predicate,'' ``subject.''
The values of these properties
are either atomic, like ``present'' and ``singular,'' or abstract
objects, like ``verb'' and ``noun-phrase.''
The abstract objects are fully described by their properties and
their values. Multiple descriptions for the properties and values
of the abstract linguistic objects are presented in the literature.
Examples are:

1.
Feature graphs, which are labeled rooted directed acyclic graphs
G=(V,A), where
F is a collection of labels,
a sink
in the graph represents an atomic value and the labeling function
is an injective function 


 .
2.
Attribute-value matrices,
which are matrices in which the
entries consist of an attribute and a value or
a reentrance symbol. The values are either atomic or
attribute-value matrices.

From a computational point of view, all descriptions that are used in
practical problems are equivalent. Though there exist some theories
 with a considerably higher expressive power . For this paper we adopt the feature graph description, which we will
define somewhat more formal in the next section.
 Attribute Value Languages(AVL)  consist of sets of logical formulas that describe classes of feature graphs,
by expressing constraints on the type of paths that can exist within
the graphs. To wit: In a sentence like ``a man walks'' the edges
labeled with ``person'' that leave the nodes
labeled ``a man'' and ``walks'' should both
end in a node labeled ``singular.'' Such a constraint is called
a ``path equation'' in the attribute-value language.

 A rewrite grammar  can be enriched with an AVL to construct an Attribute Value
Grammar(AVG), which consists of pairs of rewrite-rules and logical
formulas. The rewrite rule is applicable to a production (nonterminal)
only if the logical formula that expresses the relation between
left- and right-hand side of the rule evaluates to true.
The recognition problem for attribute-value grammars can be
stated as: Given a grammar G and a string w does there
exist a derivation in G, that respects the constraints
given by its AVL, and that ends in w.
As the intermediate productions correspond
to feature graphs this question can also be formulated as
a question about the existence of a consistent sequence of
feature graphs that results in a feature graph describing w.
For the rewrite grammar, any formalism in the Chomsky hierarchy
(from regular to type 0) can be chosen. From a computational point
of view it is of course most desirable to restrict oneself to
a formalism that on the one hand gives enough expressibility
to describe a large fragment of the (natural) language, and
on the other hand is restrictive enough to preserve feasibility.
For a discussion on the linguistic significance of such restrictions,
 see . 

 Johnson  proved that attribute-value grammars that are as restrictive as being equipped with a rewrite grammar
that is regular can already give rise to an undecidable recognition
problem.
Obviously, to be of any practical use, the
rewrite grammar or the attribute-value language must be more restrictive.
Johnson proposed to add the off-line parsability constraint,
which is respected if the rewrite grammar has no chain- or

 -rules. Then, the number of applications in a production
is linear and the size of the structure corresponding to the
partial productions is polynomial. Hence as by a modification of
 Smolka's algorithm  consistency of intermediate steps can be checked in quadratic time, the complexity of
the recognition problem can at most be (nondeterministic) polynomial
 time. This observation was made in , which also has an 


 -hardness proof of the recognition problem.

We further investigate the properties of these restricted AVGs (R-AVGs).
In the next section, we give some more formal definitions and notations.
 In Section  we show that the class of languages generated by an R-AVG (R-AVGL) includes
the class of context free languages (CFL). It follows that any easily
parsable class of languages (like CFL) is a proper
subset of R-AVGL, unless 


 .
Likewise, R-AVGL is a proper subset of the class of context
sensitive languages, unless 


 .
 In Section  we propose a further refinement on the off-line parsability constraint,
which allows R-AVGs that respect this constraint to capture
precisely complexity classes like 


or 


 .
That is, for any language L that has an 


 -parser, there exists
an R-AVG, say G, such that L=L(G). Though our refinement, the
honest parsability constraint is probably not a property that
can be decided for arbitrary R-AVGs,
we show that R-AVGs can be equipped
with restricting mechanisms that enforce this property.
 The techniques that prove Theorem  and  Theorem  result from Johnson's work. Therefore, the proofs of these theorems are deferred
to the appendices.

The definitions in this section are in the spirit
 of , Section 3.2]  and , Sections 3-4]. Consider three sets of pairwise disjoint symbols.

A, the finite set of constants, denoted (


 )

V, the countable set of variables, denoted (


 )

L, the finite set of attributes, also called features,
denoted (


 )



Definition thedefctr:
An f-edge from x to s is a triple (x,f,s) such that x is
a variable, f is an attribute, and s is a constant or a variable.
A path, p, is a, possibly empty, sequence of f-edges


  in which the xi are
variables and s is either a variable or a constant.
Often a path is denoted by the sequence of its edges' attributes,
in reversed order, e.g., 


 .
Let p be a path, ps denotes the path that starts from s,
where s is a constant only if p is the empty path. If the path
is nonempty, 


 ,
then s is a variable.
For paths
ps and qt we write 


iff p and q start in sand t respectively and end in the same variable or constant.
The expression 


is called a path equation.
A feature graph is either a pair 


 ,
or a pair (x,E) where x is the root and E a finite set of
f-edges such that:
1.
if (y,f,s) and (y,f,t) are in E, then s=t;
2.
if (y,f,s) is in E, then there
is a path from x to y in E.

Definition thedefctr:
An attribute-value language 


consists of
sets of logical formulas that describe feature graphs,
by expressing constraints on the type of paths that can exist within
the graphs.

The terms of an
attribute-value language 


are the
constants and the variables 


 .

The formulas of an attribute-value language 


 are path equations and Boolean combinations
of path equations. Thus all formulas are either 


 ,
where
ps and qt are paths, or


 ,


 ,
or 

 ,
where 

and

are formulas.



Assume a finite set 


(of lexical forms) and a finite set 


 (of categories).


will play the role of the set of terminals and 


will play the
role of the set of nonterminals in the productions.

Definition thedefctr:
A constituent structure tree (CST) is a labeled
tree in which the internal nodes are labeled with elements of Cat and the
leaves are labeled with elements of Lex.

Definition thedefctr:
Let T be a constituent structure tree and F be
a set of formulas in an attribute-value language  


 .
An annotated constituent structure tree is a triple


 ,
where h is a function that maps
internal nodes in T onto variables in F.

Definition thedefctr:
A lexicon is a finite subset of 


A set of
syntactic rules is a finite subset of


 .
An attribute-value grammar is a triple


>,
where lexicon is a lexicon, rules is a set of
syntactic rules and start is an element of 


 .

Definition thedefctr:
1.
 , p .150]  A class 

of sets is recursively presentable iff there is an
effective enumeration 


of deterministic Turing
machines which halt on all their inputs, and such that 


2.
We say that a class of grammars 

is recursively
presentable iff the class of sets 


 is recursively presentable.

The only formulas that are allowed in the attribute-value language
of restricted attribute-value grammars (R-AVGs)
are path-equations and conjunctions
of path-equations (i.e. disjunctions and negations are out). We
will denote the attribute-value language of an R-AVG by


to make the distinction clear.
The CST of an R-AVG is produced by a chain- and 

 -rule free
regular grammar. The CST of an R-AVG can be either a left-branching
or a right-branching tree, since the grammar contains
at most one nonterminal in each rule.
Definition thedefctr:
The set of syntactic rules of a restricted attribute-value
grammar is a subset of 


>.
A restricted attribute-value grammar is a pair


>,
where rules is a set of syntactic rules and start is
an element of 


 .

Definition thedefctr:
An R-AVG 


>
generates an annotated constituent structure
tree 


iff
1.
the root node of T is start, and
2.
every internal node of T is licensed by a syntactic rule, and
3.
the set F is consistent, i.e., describes a feature graph.
Let 

stand for the formula 

in which all
variable y is substituted for variable x.
An internal node v of an annotated constituent structure tree is
licensed by a syntactic rule 


 iff
1.
the node v is labeled with category c0, 

h(v) = n0, and
2.
all daughters of v are leaves, which are labeled with


 ,
and
3.


is in the set F.
An internal node v of an annotated constituent structure tree is
licensed by a syntactic rule 


 iff
1.
the node v is labeled with category c0, 

h(v) = n0, and
2.
one of v's daughters is an internal node, v1, which is
labeled with category c1, and 

h(v1) = n1, and
3.
the daughters of v that are leaves are labeled with


 ,
and
4.


is in the set F.

 In , it is shown that the recognition problem for
R-AVGs is 


 -complete. This seems to indicate that although
the mechanism for generating CSTs in R-AVGs is extremely simple, the
generative capacity of R-AVGs is different from the generative
capacity of e.g., context free languages (CFLs), which have a polynomial
 time parsing algorithm . Yet, a priori, there may exist CFLs that do not have an R-AVG.

    Let L be a context free language. There exists an
R-AVG G such that L=L(G).

Proof.If L is a context free language, then there exists
a context free grammar G' in Greibach normal form such that L=L(G').
From this grammar G', we can construct a pushdown store
M that accepts exactly the words in L(G')=L. Such a pushdown store
M is actually a finite state automaton M' with a stack S.
The finite state automaton M' may be simulated by a
chain- and 

 -rule free regular grammar.
Furthermore, we can construct an attribute-value language


that simulates the stack S.
Thus it should be clear that there exists an R-AVG G that
produces word w iff 


 .
 Details of this construction are deferred to Appendix . 

 According to Theorem , it is unlikely that the languages generated by R-AVGs can be limited to those languages with a
polynomial time recognition algorithm.
 Trautwein  showed that all R-AVGs have nondeterministic polynomial time algorithms. Is it perhaps
the case that any language that has a nondeterministic polynomial
time recognition algorithm can be generated by an R-AVG. Does
there exist a tight relation between time bounded machines and R-AVGs
as e.g., between LBAs and CSLs? The answer is that the off-line
parsability constraint that forces the R-AVG to have no chain-
or 

 -rules
is just too restrictive to allow such a connection.
The following trick to alleviate this problem has been observed earlier
in complexity theory. The off-line
 parsability constraint(OLP)  relates the amount of ``work'' done by the grammar to produce a string
linearly to the number of terminal symbols produced. It is therefore
a sort of honesty constraint that is also demanded of functions
that are used in e.g., cryptography. There the deal is, for each
polynomial amount of work done to compute the function at least
one bit of output must be produced. In such a way, for polynomial
time computable functions one can guarantee that the inverse of
the function is computable in nondeterministic polynomial time.

As a more liberal constraint on R-AVGs we propose an analogous
variation on the OLP
Definition thedefctr:
A grammar G satisfies the Honest Parsability
Constraint(HPC) iff there exists a polynomial p s.t. for each win L(G) there exists a derivation with at most 


 steps.

From Smolka's algorithm and Trautwein's observation it trivially
follows that any attribute-value grammar that satisfies the
HPC (HP-AVG) has an 


recognition algorithm. The problem with the
HPC is of course that it is not a syntactic property of grammars.
The question whether a given AVG satisfies the HPC (or the OLP for
that matter) may well be undecidable.
Nonetheless, we can produce a set of rules that,
when added to an attribute-value grammar enforces the
HPC. The newly produced language is then a subset of the old
produced language with an 


recognition algorithm.
Because of the fact that our addition may simulate any polynomial
restriction, we regain the full class of AVG's that satisfy the HPC.
In fact

Theorem  4.1   
The class, P-AVGL, of languages produced by the HP-AVGs
is recursively presentable.

We will give
a detailed construction of such a set of rules in
 Appendix . The existence of such a set of rules and the work of Johnson now gives the following theorem.

    For any language L that has an 


recognition
algorithm, there exists a
restricted attribute-value grammar G that respects
the HPC and such that L=L(G).

Proof.(Sketch)
Let M be the Turing machine that decides 

 .
Use
a variation of Johnson's construction of a Turing machine
to create an R-AVG
that can produce any string w that is recognized by M. Add the
set of rules that guarantee that only strings that can be produced
with a polynomial number of rules can be produced by the grammar.

Instead of creating a counter of logarithmic size as we do in
 Appendix , it is quite straightforward to construct a counter of linear size (or exponential size if there is enough
time). In fact, for well-behaved functions, the construction of a
counter gives a method to enforce any desired time bound constraint on
the recognition problem for attribute-value grammars.
For instance, for nondeterministic exponential time we could define
the Linear Dishonest Parsability Constraint (LDP) (allowing a linear
exponential number of steps) which would give.

Theorem  5.1   
The class of languages generated by R-AVGs obeying the
LDP condition is exactly 


 .

We are indebted to E. Aarts and W.C. Rounds for their valuable
suggestions on an early presentation of this work.

J. Balczar, J. Daz, and J. Gabarr.
Structural Complexity I.
Springer-Verlag, New York, 1988.

P. Blackburn and E. Spaan.
A modal perspective on the computational complexity of attribute
  value grammar.
Journal of Logic, Language and Information, 2(2):129-169,
  1993.

N. Chomsky.
Three models for the description of language.
IRE Transactions on Information Theory, 2(3):113-124, 1956.

J. Earley.
An efficient context-free parsing algorithm.
Communications of the Association for Computing Machinery,
  13(2):94-102, February 1970.

J. Hopcroft and J. Ullman.
Introduction to Automata Theory, Languages, and Computation.
Addison Wesley, Reading, MA, 1979.

M. Johnson.
Attribute-Value Logic and the Theory of Grammar, volume 16 of
  CSLI Lecture Notes.
CSLI, Stanford, 1988.

C. Perrault.
On the mathematical properties of linguistic theories.
Computational Linguistics, 10(3-4):165-176, 1984.

G. Smolka.
Feature-constraint logics for unification grammars.
Journal of Logic Programming, 12(1):51-87, 1992.

T. Sudkamp.
Languages and Machines: An introduction to the Theory of
  Computer Science.
Addison Wesley, Reading, MA, 1988.

M. Trautwein.
Assessing complexity results in feature theories.
ILLC Research Report and Technical Notes Series LP-95-01,
  University of Amsterdam, Amsterdam, 1995.
Submitted to the CMP-LG archive.

A context free grammar (CFG) is a quadruple


 ,
where N is a set of nonterminals,

is a set of terminals, P is a set of productions,
and 

is the start nonterminal.
A CFG is in Greibach normalform (GNF) if, and only if, the
productions are of one of the following
forms, where 


 and

 the empty string (c.f., ,  ): 

Given a GNF 


 ,
we can construct a restricted attribute-value grammar (R-AVG)
G' that simulates grammar G. R-AVG G' consists
of the same set of nonterminals and terminals as GNF G.
The productions of R-AVG G' are described by
 Table . The only two attributes of R-AVG G' are  TOP and
 REST. R-AVG G' contains |N| + 1 atomic values, one atomic
value for each nonterminal and the special atomic value $.
The R-AVG G' uses the feature graph to
encode a push-down stack, similar to the encoding of a list.
The stack will be used to store the
nonterminals that still have to be rewritten.

The three syntactic abbreviations below are used to clarify the simulation.
We use represent a stack by a Greek letter, or a string of symbols;
the top of the stack is the leftmost symbol of the string.
Let x0 encode a stack 

 ,
then the formulas in
the abbreviation 


express that x1 encodes
a stack 


 .
Likewise, the formulas in the
abbreviation 


express that x0 encodes a stack

 ,
and X1 encodes the stack 

 .
The abbreviation
 EMPTY-STACK expresses that x0 encodes an empty stack.

We have to prove that GNF Gand its simulation by R-AVG G'generate (almost) the same language. Obviously, R-AVG G'cannot generate the empty string. However,
for all non-empty strings the following theorem holds.

Theorem  6.1   
Start nonterminal S of GNF Gderives string 

(


 )
if, and only if,
start nonterminal S of R-AVG G'derives string 

with the empty stack.

Proof.There are two cases to consider. First, S derives string 

 in one step. Second, S derives string 

in more than one
step. The lemma below is needed in the proof of the second case.

Case I
Let start nonterminal S derive string 

in one step.
GNF G contains a production


iff R-AVG G'   contains a production 


with the equation
    EMPTY-STACK.
   So, S derives 

in a
   derivation of GNF G iff S derives 

with an empty stack in the derivation of R-AVG G'.
Case II
Initial nonterminal S of GNF G derives
   string 


in more than one step iff there is a
   left-most derivation 


. GNF G contains production


iff R-AVG G' contains production


with the equation
    EMPTY-STACK. By the next lemma: 


iff 


with
   the empty stack.
   Hence S derives 

for GNF G iff
   S derives 

with empty stack for R-AVG G'.

In this section we show how to add a binary counter to an
attribute-value grammar (AVG). This counter enforces the
Honest-Parsability Constraint (HPC) upon the AVG. To keep
this section legible we sometimes use the
attribute-value matrices (AVMs) as descriptions.
 In Section , we show how to create a counter for the AVG.
 In Section  we show how to extend the syntactic rules and the lexicon
of the AVG.

We start with a little bit of arithmetic.

The AVMs below encode natural numbers in binary
notation.  The sequences of attributes  0 and  1 in these
AVMs
encode natural numbers, from least- to most-significant bit.
The attribute  V has value 1 (or 0) if, and only if,
it has a sister attribute  1 (or  0).
1.
The AVMs 


and 


        encode the natural numbers zero and one.
2.
The AVMs 


        and 


encode
        natural numbers iff the AVM [F] encodes a natural number.

Assume a nonterminal A with some AVM


 ,
where [F] and [H] encode
natural number x and y, respectively.
We present one syntactic rule that derives from this
nonterminal A a nonterminal B with AVM


if x = y.

Clearly, this simple test takes one step. A more sophisticated
test, which also tests for inequality, would compare [F]and [G] bit-by-bit.  Such a test would take




 derivation steps.

Assume a nonterminal A with some AVM


 ,
where [F] encodes natural number x.
We present one syntactic rule that derives from this
nonterminal A a nonterminal B with the AVM


 ,
where [H] encodes natural number 2x.

The number  N in [H] equals two times  N in [F]if, and only if, the least-significant bit of  N in [H]is 0, and the remaining bits form the same sequence as the
number  N in [F]. Multiplication by two takes one derivation
step.

Assume a nonterminal A with some AVM


 ,
where [F] encodes natural number x.
We present five syntactic rules that derive from this
nonterminal A a nonterminal C with AVM


 ,
where [H] encodes natural number x+1.

The increment of  N requires two additional pointers in the
AVM of A: attribute  P points to the next bit
that has to be incremented; attribute  Q points to the
most-significant bit of the (intermediate) result.
These additional pointers are hidden from the
AVMs of the nonterminals A and C.

 The five rules from Table  increment  N by one. Nonterminal A rewrites, in one or more steps, to nonterminal
C, potentially through a number of nonterminals B.

 The first and fourth rule of Table  state that adding one to a zero bit sets
this bit to one and ends the increment. The second and third rule state
that adding one to a one bit sets this bit to zero and the increment
continues.  The fifth rule states that adding one to the
most-significant bit
sets this bit to zero and yields a new most-significant one bit.
We claim that 


 takes 


derivation steps.

Rules, similar to the ones above, can be given that decrement
the attribute  N by one. We only have to take a little
extra care that the number 0 cannot be decremented.

In this section we use the previous test and increment rules
(indicated by =).
Assume a nonterminal A with some AVM


 ,
where [F] and [H] encode
natural number x and y, respectively.
 We present syntactic rules (Table -) that derive from this
nonterminal A a nonterminal C with AVM


 ,
 where [F'] encodes the natural number x + y.

The increment of  N by  M is similar to the
increment by one. Here, three additional pointers are required:
the attributes  P and  Q point to the bits in  N and
 M respectively that have to be summed next; attribute  R
points to the most-significant bit of the (intermediate) result.
In the addition two states
are distinguished. In the one state, the carry bit is zero, indicated
by nonterminal A'. In the other state, the carry bit is one,
indicated by nonterminal B.
We claim that 


 takes 


 derivation steps.

In this section we use the previous summation rules
(indicated by =).
Assume a nonterminal A with some AVM


 ,
where [F'] encodes a list of numbers. To wit

where [Gi] encodes natural number xi.
 We present syntactic rules (Table ) that derive from this nonterminal A a nonterminal B with AVM


 ,
where [F] encodes the natural number 


 .

The summation requires an additional pointer in the
AVM [F']: attribute  P points to the next element
in the list that has to be summed.
We claim that 


 takes 


derivation steps.

Create an AVM of the following form:

Attribute  COUNTER is used to distinguish the AVMs
that encodes the counter from those in the
original attribute-value grammar. We will neglect the
attribute  COUNTER in the remainder of this section, because it is
not essential here.
The attributes  SIZE,  N,  M and  POLY
encode natural numbers.
The attribute  SIZE records the size of the string that will be
generated.  The attribute  POLY records the maximum number of
derivation steps that is allowed for a string of size  SIZE.
The attributes  N and  M are auxiliary numbers.

The construction of the counter starts with an initiation-step.
The further construction of the counter consists of cycles of two
phases. Each cycle starts in nonterminal A.

The initiation-step sets the numbers  SIZE and  N to 0,
and the numbers  M and  POLY to 1.
In the first phase of each cycle, the numbers  SIZE and  N
are incremented by 1.

In this phase the numbers  N and  M are compared.
If  N is twice  M, then (i) number
 POLY is extended by k bits, (ii) number  M is doubled,
and (iii) number  N is set to 0.
If  N is less than twice  M, nothing happens.

The left rule of the second phase doubles the number  M in
the second and the third equation.
The test ``Is  N equal to 2 M?'' therefore reduces to one
(the first) equation.
The fourth equation extend the number  POLY with k bits.
The fifth and sixth equations set the number  N to 0.

The right rule is always applicable. If the right rule is used where
the left rule was applicable, then the number  N will never be
equal to 


in the rest of the derivation. Thus  POLY will
not be extended any more.

We claim that the left rule appears 

times and the right
rule O(n) times in a derivation for input of size n.
Obviously, the number  POLY is 


when
the number  SIZE is i.

In this section we show how to transform an AVG
into an AVG that satisfies the HPC (HP-AVG).
Since all computation steps of the HP-AVG
only require a linear amount of derivation steps,
total derivations of HP-AVGs have polynomial length.

We can divide the attributes of the HP-AVG into two groups. The
attributes that encode the counters, and the attributes of the
original AVG. The former will be embedded under the attribute
 COUNTER, the latter under the attribute  GRAMMAR.
In the sequel, we mean by 


the formula 

 embedded under the attribute  GRAMMAR, i.e., the formula
obtained from 

by substituting the variables xi by


 .

The HP-AVG is obtained from the AVG in three steps: change
the start nonterminal, the lexicon and the syntactic rules.
First, the HP-AVG contains the rules of the previous section, which
 construct the counter. The nonterminal S from Table  is the start nonterminal of the HP-AVG. For the nonterminal A the start
 nonterminal of the AVG is taken. Nonterminal B from Table  is a fresh nonterminal, not occurring in the AVG.

Second, the HP-AVG contains an extension of the lexicon of the AVG.
The entries of the lexicon are extended in the following way. The size
of the lexical form is set to one, and the amount of derivation steps
is zero. Thus, if 


is the lexicon of the AVG,
then 


is the lexicon of the HP-AVG, where

Third, the HP-AVG contains extensions of the syntactic rules of the AVG.
The syntactic rules are extended in the following way. The numbers
 POLY and  SIZE of the daughter nonterminals are collected in
the lists  PLIST and  SLIST. Both lists are summed.
The number  SIZE of the mother nonterminal is equal to
the sum of  SIZE's,
and the number  POLY of the mother nonterminal is one
more than the sum of  POLY's.
Thus, if 


 is a syntactic rule of the AVG, then 


 is a syntactic rule of the HP-AVG, where

Now, a derivation for the HP-AVG starts with a nondeterministic
construction of a counter  SIZE with value n and a counter
 POLY with value O(n[k]). Then, the derivation of the original
AVG is simulated, such that
(i)
 the mother nonterminal produces a string of size n if, and only if
 the daughter nonterminals together produce a string of size n, and
(ii)
 the mother nonterminal makes n[k]+1 derivation steps if, and only if
 the daughter nonterminals together make n[k] derivation steps.

  The author was supported in part by HCM grant
        ERB4050PL93-0516.
  The author was supported by the Foundation for language,
        speech and logic (TSL), which is funded by the Netherlands
        organization for scientific research (NWO)
